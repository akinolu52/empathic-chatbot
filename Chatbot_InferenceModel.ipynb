{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b109eba-6f49-4b92-9a5f-89d85171ab03",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9411524-a449-4f91-831e-90eb2a6fbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828c2059-9662-494b-ae03-8ce70bb53c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import os \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate, dot, Activation, Lambda, Input, Embedding, LSTM, Dense\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dot, Activation, Add\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd59784-ff19-4df5-bd17-38d0bd56a5f1",
   "metadata": {},
   "source": [
    "### 1. Load Trained Model and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ebde82-3480-4a17-bb56-e4a0fc586ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model \n",
    "model_50b = load_model('model_50b.h5')\n",
    "\n",
    "#load tokenizer.word_index\n",
    "#with open('tokenize_word_index.pkl', 'rb') as file:\n",
    "    #tokenize_word_index = pickle.load(file)\n",
    "\n",
    "# Load the tokenizer from the file\n",
    "with open('tokenizer_50b.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "# This is for ease of assignment; previously loaded just the word_index and not the tokenizer itself\n",
    "#tokenize_word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d63952-1a65-4a25-9d7c-8adae5769798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 77)]         0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 77)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_34 (Embedding)       (None, 77, 64)       1570432     ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_35 (Embedding)       (None, 77, 64)       1570432     ['input_36[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_34 (LSTM)                 [(None, 77, 128),    98816       ['embedding_34[0][0]']           \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_35 (LSTM)                 [(None, 77, 128),    98816       ['embedding_35[0][0]',           \n",
      "                                 (None, 128),                     'lstm_34[0][1]',                \n",
      "                                 (None, 128)]                     'lstm_34[0][2]']                \n",
      "                                                                                                  \n",
      " dot_34 (Dot)                   (None, 77, 77)       0           ['lstm_35[0][0]',                \n",
      "                                                                  'lstm_34[0][0]']                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 77, 77)       0           ['dot_34[0][0]']                 \n",
      "                                                                                                  \n",
      " dot_35 (Dot)                   (None, 77, 128)      0           ['activation_17[0][0]',          \n",
      "                                                                  'lstm_34[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 77, 256)      0           ['lstm_35[0][0]',                \n",
      "                                                                  'dot_35[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 77, 24538)    6306266     ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,644,762\n",
      "Trainable params: 9,644,762\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_50b.summary()) #for reference in extracting correct layers for inference model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5258e-8bf1-456e-9d00-98a3b5f5478b",
   "metadata": {},
   "source": [
    "### 2. Build Chatbout Inference Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e56f23-95da-4286-ba47-63053222b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128 #dimension for hidden layer, as set in train model\n",
    "output_dim = 64 #dimension for output , as set in train model\n",
    "maxlen = model_50b.input_shape[1][1]\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
    "#tokenizer = Tokenizer()\n",
    "\n",
    "# Extract the Decoder embedding, LSTM, and dense layers and create an instance of each\n",
    "decoder_embedding_layer = model_50b.get_layer('embedding_35')\n",
    "decoder_lstm_layer = model_50b.get_layer('lstm_35')\n",
    "decoder_dense_layer = model_50b.get_layer('dense_17')\n",
    "#decoder_dense_layer = Dense(VOCAB_SIZE, activation='softmax', name='dense_9')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e19f3b5-dd39-4096-9960-86429c39a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_layer(enc_out, dec_out):\n",
    "    #calculate the attention scores\n",
    "    attn_score = dot([dec_out, enc_out], axes = [2,2])\n",
    "    attention_weights = Activation('softmax')(attn_score)\n",
    "\n",
    "    #calculate the context vector\n",
    "    context_vector = dot([attention_weights, enc_out],axes=[2,1])\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291bc8c4-32f6-4584-a963-c7b775ad0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference Encoder and Decoder Model\n",
    "\n",
    "\n",
    "#Encoder\n",
    "encoder_inputs = model_50b.input[0]\n",
    "encoder_outputs, state_h, state_c = model_50b.layers[4].output\n",
    "encoder_states = [state_h, state_c]\n",
    "#encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model = Model(encoder_inputs,[encoder_outputs] + encoder_states)\n",
    "\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = tf.keras.Input(shape=(1,),dtype=tf.float32, name='decoder_inputs')\n",
    "\n",
    "#tensors for decoder's LSTM state\n",
    "decoder_state_input_h = tf.keras.Input(shape = (hidden_dim, ), dtype=tf.float32, name = 'decoder_state_input_h') #name included to help properly identify the state during processing\n",
    "decoder_state_input_c = tf.keras.Input(shape = (hidden_dim, ), dtype=tf.float32, name = 'decoder_state_input_c') #name included to help properly identify the state during processing\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs) #using same decoder_embedding from training on decoder_inputs_inference\n",
    "\n",
    "#LSTM decoder with initial state\n",
    "decoder_outputs, state_h, state_c = decoder_lstm_layer(decoder_embedding, initial_state = decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "#encoder_outputs that will be fed during inference\n",
    "encoder_outputs_input = Input(shape=(None, hidden_dim), name='encoder_outputs')\n",
    "\n",
    "#Calculate the attention context vector values\n",
    "context_vector, attention_weights = attn_layer(encoder_outputs_input, decoder_outputs)#(encoder_outputs_input, decoder_outputs)\n",
    "\n",
    "# Combine the context vector with the decoder outputs\n",
    "decoder_combined_context = Concatenate(axis = -1)([decoder_outputs, context_vector])\n",
    "\n",
    "#Dense layer for final output\n",
    "decoder_outputs = decoder_dense_layer(decoder_combined_context)\n",
    "\n",
    "#Inference decoder model\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs + [encoder_outputs_input],[decoder_outputs] + decoder_states, name = 'decoder_model')\n",
    "#decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states, name = 'decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f3ab54-ed54-4c91-bba5-cd1ee30e70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of decoder_outputs: (None, 1, 24538)\n",
      "Shape of context_vector: (None, 1, 128)\n",
      "Shape of decoder_combined_context: (None, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of decoder_outputs:\", decoder_outputs.shape)\n",
    "print(\"Shape of context_vector:\", context_vector.shape)\n",
    "print(\"Shape of decoder_combined_context:\", decoder_combined_context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4903a1-f7e8-4415-acdf-80b345c013d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_inputs (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_35 (Embedding)       multiple             1570432     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_state_input_h (InputLa  [(None, 128)]       0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " decoder_state_input_c (InputLa  [(None, 128)]       0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " lstm_35 (LSTM)                 multiple             98816       ['embedding_35[1][0]',           \n",
      "                                                                  'decoder_state_input_h[0][0]',  \n",
      "                                                                  'decoder_state_input_c[0][0]']  \n",
      "                                                                                                  \n",
      " encoder_outputs (InputLayer)   [(None, None, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, None)      0           ['lstm_35[1][0]',                \n",
      "                                                                  'encoder_outputs[0][0]']        \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, None)      0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1, 128)       0           ['activation[0][0]',             \n",
      "                                                                  'encoder_outputs[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 256)       0           ['lstm_35[1][0]',                \n",
      "                                                                  'dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               multiple             6306266     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,975,514\n",
      "Trainable params: 7,975,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affceb03-491f-4f01-9c88-b34733e8a8f6",
   "metadata": {},
   "source": [
    "### 3. Chatbot Response Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a6a4f-d221-4c1b-a778-582d40b5541d",
   "metadata": {},
   "source": [
    "### 3.a. Text preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d393e3-ba3f-4489-83f3-c34580c3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of contractions and their expansions\n",
    "contractions_dict = {\"don't\": \"do not\",\"can't\": \"cannot\",\"won't\": \"will not\",\"wouldn't\": \"would not\",\n",
    "                          \"shouldn't\": \"should not\",\"couldn't\": \"could not\",\"it's\": \"it is\",\"i'm\": \"i am\",\n",
    "                          \"you're\": \"you are\",\"there's\" : \"there is\",\"he's\": \"he is\",\"she's\": \"she is\",\n",
    "                          \"we're\": \"we are\",\"they're\": \"they are\",\"wasn't\": \"was not\",\"weren't\": \"were not\",\n",
    "                          \"hasn't\": \"has not\",\"haven't\": \"have not\",\"hadn't\": \"had not\",\"mightn't\": \"might not\",\n",
    "                          \"shan't\": \"shall not\",\"mustn't\": \"must not\",\"isn't\":\"is not\",\"didn't\":\"did not\",\"aren't\":\"are not\",\n",
    "                          \"oughtn't\":\"ought not\",\"needn't\":\"need not\", \"could've\":\"could have\", \"should've\":\"should have\",\n",
    "                          \"would've\":\"would have\",\"might've\":\"might have\",\"i've\":\"i have\",\"you've\":\"you have\",\"we've\":\"we have\",\n",
    "                          \"they've\":\"they have\",\"i'll\":\"i will\",\"you'll\":\"you will\",\"he’ll\":\"he will\",\"she’ll\":\"she will\",\n",
    "                          \"it’ll\":\"it will\",\"we’ll\":\"we will\",\"they’ll\":\"they will\",\"i’d\":\"i had\",\"you’d\":\"you had\",\n",
    "                          \"she’d\":\"she had\",\"he’d\":\"he had\",\"it'd\":\"it had\", \"we'd\":\"we had\",\"they'd\":\"they had\",\"that's\":\"that is\",\n",
    "                          \"that’ve\":\"that have\",\"that’d\":\"that would\",\"which’ve\":\"which have\",\"who’s\":\"who is\",\"who’re\":\"who are\",\n",
    "                          \"who’ve\":\"who have\",\"who’d\":\"who had\",\"who'll\":\"who will\",\"what’s\":\"what is\",\"what’re\":\"what are\",\n",
    "                          \"what’ll\":\"what will\",\"where’s\":\"where is\",\"where’d\":\"where did\",\"when’s\":\"when is\",\"why’s\":\"why is\",\n",
    "                          \"why’d\":\"why did\",\"how’s\":\"how is\",\"here’s\":\"here is\",\"there’s\":\"there is\",\"there’ll\":\"there will\",\n",
    "                          \"there’d\":\"there had\",\"someone’s\":\"someone is\",\"somebody’s\":\"somebody is\",\"no one’s\":\"no one is\",\"nobody’s\":\"nobody is\",\n",
    "                          \"something’s\":\"something is\",\"nothing’s\":\"nothing is\",\"let’s\":\"let us\",\"ma’am\":\"madam\",\"o'clock\":\"of the clock\", \"let's\":\"let us\",\n",
    "                          \n",
    "}\n",
    "\n",
    "# Create a regular expression pattern from the contractions dictionary\n",
    "contractions_pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
    "\n",
    "# Define a function to replace contractions using the pattern\n",
    "#def expand_contractions(text):\n",
    "    #return contractions_pattern.sub(lambda x: contractions_dict[x.group(0)], text)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    word_contraction = lambda x: dict_word_contractions[x.group(0)] #locates contraction in dictionary\n",
    "    result = re.sub(contractions_pattern, word_contraction,text) #finds and replace contraction in text with equivalent word/phrase\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198bc22b-ff33-46e1-9239-720823314f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instances needed for preprocessing function\n",
    "\n",
    "patterns = re.compile(pattern = \"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons \n",
    "                                       u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                       u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                       u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                       \"]+\", flags = re.UNICODE)\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6390d7b9-ed10-41cd-8e63-b6c0e1145f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    '''Preprocessing of text, steps covered:\n",
    "    1. transform to lower case\n",
    "    2. remove punctuations, numbers, emojis, unwanted characters\n",
    "    3. tokenize text\n",
    "    4. lemmatize text\n",
    "    '''\n",
    "        \n",
    "    text = text.lower() #convert to lowercase\n",
    "\n",
    "    text = replace_contractions(text) #replace word contractions\n",
    "    #text= spell_check(text) #correct spelling errors\n",
    "    text.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "    text = re.sub(patterns,'', text)\n",
    "    #text = re.sub('<!@.*?>', '', text) #remove unwanted characters \n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) #remove numbers\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
    "    text = re.sub(r\"\\s+\", r\" \", text).strip()\n",
    "    \n",
    "    text = nlp(text)\n",
    "\n",
    "    # Perform lemmatization, removing stop words and non-alphabetic tokens\n",
    "    cleaned = [token.lemma_ for token in text if token.is_alpha]\n",
    "    \n",
    "    #tokenized_words = word_tokenize(text) #tokenize text\n",
    "    #cleaned = [lemmatizer.lemmatize(token) for token in tokenized_words] # #create list of cleaned lemmatized words\n",
    "    \n",
    "    \n",
    "    return ' '.join(cleaned) # create list of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972fac1-d5b3-42fd-b75f-cb9ea8d022b8",
   "metadata": {},
   "source": [
    "### 3.b Engage with Chatbot/ Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02a31e48-bba8-4c61-8f5e-017439101999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response():\n",
    "        \n",
    "    user_input = input(\"Say something Emobot would like to chat with you: \")\n",
    "    \n",
    "    #preprocess user input \n",
    "    clean_input = preprocessing(user_input)\n",
    "    clean_input_seq = tokenizer.texts_to_sequences([clean_input])\n",
    "    clean_input_seq = pad_sequences(clean_input_seq, maxlen = maxlen, padding = \"post\")\n",
    "    \n",
    "    #chatbot response\n",
    "    encoder_outputs, state_h, state_c = encoder_model.predict(clean_input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tokenizer.word_index.get('<start>',1)\n",
    "    \n",
    "    # placeholder for response sequence\n",
    "    stop_condition = False\n",
    "    response_seq = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        #predict next word in sequence\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [state_h, state_c] +[encoder_outputs])\n",
    "        #output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
    "        #print(f\"Output tokens: {output_tokens}\")\n",
    "        \n",
    "        #get predicted word index\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        #print(f\"Sampled token index: {sampled_token_index}\")\n",
    "        \n",
    "        response_seq.append(sampled_token_index)\n",
    "        #for idx in response_seq:\n",
    "            #print(f\"Token index: {idx}, Word: {tokenizer.index_word.get(idx, '<unk>')}\")\n",
    "        \n",
    "        #exit condition by either hitting max length or found stop token\n",
    "        if sampled_token_index == tokenizer.word_index.get('<end>',2) or len(response_seq) > maxlen:\n",
    "            stop_condition = True\n",
    "        \n",
    "       \n",
    "        #update the target sequence    \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        #update states\n",
    "        states_value =[h, c] \n",
    "        #documents = SimpleDirectoryReader(directory_path).load_data\n",
    "        \n",
    "    #Transform response sequence to text\n",
    "    #print(f\"Raw response sequence: {response_seq}\")\n",
    "    responses = tokenizer.sequences_to_texts([response_seq])[0]\n",
    "    #print(f\"Final response text: {responses}\")\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e202ee0-ad51-4907-b5d0-a86a167a82d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Say something Emobot would like to chat with you:  hi how are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not you do not'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chatbot_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b6850-af9f-45b3-8391-0dc5fdc715a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58861c9-4935-4699-a6b0-885c8b4a2708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
